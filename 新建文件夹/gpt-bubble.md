从 ChatGPT 横空出世到最近的环比增量统计，环比访问增长仅 2.8%, 在加上前阵子杨立昆一顿输出，投资界对 AI 大模型的看法也开始产生分歧，结合我个人使用 ChatGPT 的经验，我预感人们对 AI 大模型正在从不切实际的期望回归理性。
前不久，李彦宏提到本轮 AI 的竞争力并不是说拥有多少大模型，而是能产生多少基于大模型的 AI 原生应用，但从实际情况看，目前基于大模型的 AI 应用并没有呈现出投资界预期的所谓 iPhone 时刻。
而这一切只能说是成也大模型，败也大模型
众所周知，ChatGPT 的原理可以简单解释为对字符的预测，在 openai 的课程上你可以反复的听到这样的教导，明确的指令，不要让 AI 猜测你的意图，对于复杂的问题，需要拆解成小的问题，然后逐步引导 AI 理解问题的整体解决过程诸如此类，事实上归根结底包括 ChatGPT 的设置参数背后都透露出一个不争的事实
大模型所表现出的能力并不是大众所理解的智能，更多是一种玄学，我们通过提示词对大模型进行编程，引导大模型回答出我们想要的答案，但在很多事实领域，尤其是需要精确回答的领域，即便我们使出浑身解数，大模型依然可能像个叛逆的孩子给你来一段 freestyle。
对此，我们称之为幻觉，至少在编程领域，我从来没遇到过幻觉，最多就是个 BUG，但 BUG 遵循因果律，只是可能链条很复杂，但是幻觉就上升到精神领域了，ChatGPT 胡说八道那可是出了名的，事实上如果你只要一个聊天对象，那幻觉也可以理解成幽默，但是如果把 ChatGPT 放到精确处理的领域，有时候未必比某些专属的小模型强到哪去，重点是这些领域本来就已经比较成熟了。
至少大众对大模型的期望是，人工智能应该比人强，但是比人强这个事情，你要分开来看，是全面比人强，还是说部分比人强，目前看来大模型的优势是数据优势，相比人类而言，大模型的知识总量更加庞大，如果把大模型比做人，那么这个人就有这么几个特征

博闻强记，你问啥他都知道
不懂装懂，说谎不打草稿
无论 GPT 到几代都没有常识可严，因为常识是不变的，但是大模型的回答是不可能不变的。

因此 openai 一直努力在给大模型增加工具以解决常识问题，openai 的文档上明确提到，如果某项工作已经有工具能够做得很好，那么就应该交给工具来做，而不是大模型，从而发挥两者的长处，这也是整个 plugin 设计的由来，但对于人类而言，发明工具，改进工具，才促使我们不断改善我们的技术，从这个角度看大模型也很难比人强，因为他永远不会有动力去改进这些 plugin。
因为在 ChatGPT 之前并没有出现过能给人带来良好体验的聊天机器人，ChatGPT 的出现放大了人们对人工智能的期望，就好像
"看，他都能跟我这么流畅的对话，可比一些人强多了！"
或许这就是大模型带给人们的幻觉，其实生活中也存在这类人，特别能说，夸夸其谈，但是一旦干点啥，就特别不靠谱。
大模型是否能转变成真正的人工智能？从 ChatGPT 到 AGI 会是人类的幻觉么，或许答案已经不远了。
